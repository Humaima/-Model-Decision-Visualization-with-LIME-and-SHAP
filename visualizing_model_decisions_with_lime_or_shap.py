# -*- coding: utf-8 -*-
"""Visualizing Model Decisions with LIME or SHAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17qoRCWjfio3h4oYeAYKbszs9cpdnyW1E

**Install Packages**
"""

!pip install pandas scikit-learn lime shap matplotlib seaborn

"""**Project Overview**

1. Train two models (Logistic Regression and Random Forest) on a dataset (Iris first).
2. Produce local explanations for individual predictions using LIME and SHAP.
3. Visualize explanations (bar plots, waterfall).
4. Compute simple comparison metrics between explainers:
*   Spearman rank correlation of absolute importances.
*   Top-k overlap (e.g., top 2 or top 3 features matching).
5. Repeat on Titanic (requires preprocessing) to show a real dataset.


"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# Explainers
from lime.lime_tabular import LimeTabularExplainer
import shap

# Loading the dataset
iris = load_iris(as_frame=True)
X = iris.frame[iris.feature_names]
y = iris.frame["target"]
feature_names = iris.feature_names
class_names = iris.target_names.tolist()

# Train/test Split + Scaling for Logistic Regression
X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, stratify=y, test_size=0.2)
scaler = StandardScaler().fit(X_train)
X_train_s = pd.DataFrame(scaler.transform(X_train), columns=feature_names)
X_test_s = pd.DataFrame(scaler.transform(X_test), columns=feature_names)

# Training Models
log = LogisticRegression(max_iter=1000).fit(X_train_s, y_train)
rf = RandomForestClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)   # tree model works without scaling

# Model Evaluation
for name, model, Xt in [('Logistic', log, X_test_s), ('RandomForest', rf, X_test)]:
    preds = model.predict(Xt)
    print(f"{name} accuracy:", accuracy_score(y_test, preds))

# Now, pick an instance to explain
idx = 3
x = X_test.iloc[idx:idx+1]           # for RF (unscaled)
x_s = X_test_s.iloc[idx:idx+1]       # for logistic

print("Instance features:", x.to_dict(orient='records')[0])

# LIME Explanations
# For LIME we provide the unscaled data and a prediction function that returns probabilities.
explainer = LimeTabularExplainer(
    training_data=X_train.values,
    feature_names=feature_names,
    class_names=class_names,
    mode='classification',
    discretize_continuous=True,
    random_state=42
)

# LIME for RandomForest
exp_rf = explainer.explain_instance(x.values.flatten(), rf.predict_proba, num_features=4)
print("LIME (RF) explanation:", exp_rf.as_list())

# LIME for Logistic (wrap scaler + predict_proba)
def log_predict_proba_unscaled(unscaled_array):
    # unscaled_array shape (n_samples, n_features)
    scaled = scaler.transform(unscaled_array)
    return log.predict_proba(scaled)

exp_log = explainer.explain_instance(x.values.flatten(), log_predict_proba_unscaled, num_features=4)
print("LIME (Logistic) explanation:", exp_log.as_list())

# SHAP explanations
# For RandomForest use TreeExplainer (fast)
rf_explainer = shap.TreeExplainer(rf)
shap_values_rf = rf_explainer.shap_values(x)  # list per class for multiclass

# For Logistic, use KernelExplainer (or LinearExplainer if available)
log_explainer = shap.KernelExplainer(lambda z: log.predict_proba(scaler.transform(z)), X_train_s.iloc[:100,:])  # background subset
shap_values_log = log_explainer.shap_values(x_s, nsamples=100)  # keep nsamples modest

print(f"SHAP RF type: {type(shap_values_rf)}, length: {len(shap_values_rf) if hasattr(shap_values_rf, '__len__') else 'N/A'}")
print(f"SHAP Logistic type: {type(shap_values_log)}, length: {len(shap_values_log) if hasattr(shap_values_log, '__len__') else 'N/A'}")

pred_class_rf = rf.predict(x)[0]
pred_class_log = log.predict(x_s)[0]

print(f"Predicted class RF: {pred_class_rf}, Logistic: {pred_class_log}")

# Handle different SHAP value formats
# For Random Forest (TreeExplainer with multiclass)
if isinstance(shap_values_rf, list):
    # TreeExplainer returns list of arrays for multiclass
    shap_rf_abs = np.abs(shap_values_rf[pred_class_rf]).flatten()
else:
    # If it's a single array, use it directly
    shap_rf_abs = np.abs(shap_values_rf).flatten()

# For Logistic Regression (KernelExplainer)
if isinstance(shap_values_log, list):
    # KernelExplainer returns list for multiclass
    shap_log_abs = np.abs(shap_values_log[pred_class_log]).flatten()
else:
    # If it's a single array, use it directly
    shap_log_abs = np.abs(shap_values_log).flatten()

print(f"SHAP RF abs shape: {shap_rf_abs.shape}, values: {shap_rf_abs}")
print(f"SHAP Logistic abs shape: {shap_log_abs.shape}, values: {shap_log_abs}")

# Prepare feature importances from SHAP absolute values for the predicted class
pred_class_rf = rf.predict(x)[0]
pred_class_log = log.predict(x_s)[0]

# Correctly extract SHAP values for the predicted class and flatten
shap_rf_abs = np.abs(shap_values_rf[:, :, pred_class_rf]).flatten()
shap_log_abs = np.abs(shap_values_log[:, :, pred_class_log]).flatten()

# Convert to pandas series for plotting and comparison
shap_rf_series = pd.Series(shap_rf_abs, index=feature_names).sort_values(ascending=False)
shap_log_series = pd.Series(shap_log_abs, index=feature_names).sort_values(ascending=False)

display(shap_rf_series)
display(shap_log_series)

# Plot side-by-side
fig, axes = plt.subplots(1,2, figsize=(12,4))
shap_rf_series.plot.bar(ax=axes[0], title='SHAP abs (RF) - instance')
shap_log_series.plot.bar(ax=axes[1], title='SHAP abs (Logistic) - instance')
plt.tight_layout()
plt.show()

# Convert LIME explanation into a comparable numeric vector (feature -> weight)
def lime_list_to_series(lime_exp, feature_names):
    # lime_expl.as_list() returns list of (feature_html, weight)
    items = lime_exp.as_list()
    s = pd.Series(0.0, index=feature_names)
    for feat_label, weight in items:
        # feat_label like "petal length (cm) <= 2.45" or "sepal length (cm) > 5.0"
        # Find best matching feature name
        matched = [fn for fn in feature_names if fn in feat_label]
        if matched:
            s[matched[0]] += weight
    return s

lime_rf_series = lime_list_to_series(exp_rf, feature_names).abs().sort_values(ascending=False)
lime_log_series = lime_list_to_series(exp_log, feature_names).abs().sort_values(ascending=False)

print("LIME RF abs weights:\n", lime_rf_series)
print("LIME Logistic abs weights:\n", lime_log_series)

# Compare rankings: Spearman correlation and top-k overlap
from scipy.stats import spearmanr

def compare_importances(series_a, series_b, k=2):
    # series_a and series_b indexed by feature name; ensure same ordering
    s_a = series_a.reindex(feature_names).fillna(0)
    s_b = series_b.reindex(feature_names).fillna(0)
    rho, p = spearmanr(s_a.values, s_b.values)
    topk_a = set(s_a.sort_values(ascending=False).head(k).index)
    topk_b = set(s_b.sort_values(ascending=False).head(k).index)
    topk_overlap = len(topk_a & topk_b)
    return rho, p, topk_overlap, topk_a, topk_b

rho_rf, p_rf, overlap_rf, top_a_rf, top_b_rf = compare_importances(shap_rf_series.abs(), lime_rf_series, k=2)
print("RF compare (SHAP vs LIME): spearman rho=", rho_rf, " top2 overlap=", overlap_rf, top_a_rf, top_b_rf)

rho_log, p_log, overlap_log, top_a_log, top_b_log = compare_importances(shap_log_series.abs(), lime_log_series, k=2)
print("Logistic compare (SHAP vs LIME): spearman rho=", rho_log, " top2 overlap=", overlap_log, top_a_log, top_b_log)

"""# Front End"""

!pip install gradio shap lime scikit-learn matplotlib

import gradio as gr
import shap
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from lime.lime_tabular import LimeTabularExplainer

iris = load_iris(as_frame=True)
X = iris.frame[iris.feature_names]  # Use the DataFrame part of the Bunch object
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)
scaler = StandardScaler().fit(X_train)
log = LogisticRegression(max_iter=1000).fit(scaler.transform(X_train), y_train)

explainer = shap.KernelExplainer(lambda z: log.predict_proba(scaler.transform(z)), X_train.iloc[:100,:])
lime_exp = LimeTabularExplainer(X_train.values, feature_names=X.columns, class_names=iris.target_names, mode='classification')

def explain(sample_index):
    x = X_test.iloc[[sample_index]]
    shap_values = explainer.shap_values(scaler.transform(x))
    shap.summary_plot(shap_values, x, show=False)
    plt.tight_layout()
    plt.savefig("shap_plot.png"); plt.close()

    exp = lime_exp.explain_instance(x.values.flatten(), lambda z: log.predict_proba(scaler.transform(z)))
    fig = exp.as_pyplot_figure()
    plt.tight_layout()
    plt.savefig("lime_plot.png"); plt.close()

    return "shap_plot.png", "lime_plot.png"

demo = gr.Interface(
    fn=explain,
    inputs=gr.Slider(0, len(X_test)-1, 0, step=1, label="Sample Index"),
    outputs=[gr.Image(label="SHAP Explanation"), gr.Image(label="LIME Explanation")],
    title="Visualizing Model Decisions with LIME and SHAP"
)

demo.launch()